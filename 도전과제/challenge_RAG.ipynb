{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch3 LLM, RAG 개인 도전과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal: LangSmith의 Prompt Library를 참고하여 prompt engineering을 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 사용환경 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"  # 라이브러리끼리의 충돌을 해결"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. 모델 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 모델 초기화\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. 문서 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader = PyPDFLoader(\"files/인공지능산업최신동향_2024년_11월호.pdf\")\n",
    "\n",
    "# 페이지 별 문서 로드\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. 문서 청크로 나누기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RecursiveCharacterTextSplitter**\n",
    "- 주어진 문자 목록의 순서대로 청크가 충분히 작아질 때까지 재귀적으로 텍스트를 분할하는 클래스\n",
    "- 문자 목록을 매개변수로 받아 동작\n",
    "- 기본 문자 목록: \\[\"\\n\\n\", \"\\n\", \" \", \"\"\\] (default)\n",
    "- 텍스트를 재귀적으로 분할하여 의미적으로 관련있는 텍스트 조각들이 같이 있도록 하는 목적으로 설계됨\n",
    "\n",
    "---\n",
    "- `chunk_size`: 각 청크의 최대 길이\n",
    "- `chunk_overlap`: 인접한 청크 사이에 중복으로 포함될 문자의 수\n",
    "- `length_function`: 청크의 길이를 계산하는 함수\n",
    "- `is_separator_regex`: 구분자로 정규식을 사용할지 여부를 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "splits = recursive_text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. 벡터 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. 벡터 스토어 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. FAISS를 Retriever로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 도전 구현 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### i. LangSmith의 Prompt Library 를 참고하여 프롬프트를 3개 이상 아래와 같은 파일 구조로 저장해주세요. \n",
    "``` bash\n",
    ".\n",
    "├── main.jupynb\n",
    "└── Prompts/\n",
    "    ├── prompt1.txt\n",
    "    ├── prompt2.txt\n",
    "    └── prompt3.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3_envs\\SpartaProjects\\Personal_Project\\project2\\Lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "d:\\Anaconda3_envs\\SpartaProjects\\Personal_Project\\project2\\Lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "d:\\Anaconda3_envs\\SpartaProjects\\Personal_Project\\project2\\Lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LangChain library에서 prompt, model, chain, agent 등을 불러오는 라이브러리\n",
    "from langchain import hub\n",
    "\n",
    "# Prompts 디렉토리가 없다면 Prompts 디렉토리 만들기\n",
    "os.makedirs(\"Prompts\", exist_ok=True)\n",
    "\n",
    "# hub.pull() 함수로 LangChain library에서 prompt 가져오기\n",
    "prompt1 = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt2 = hub.pull(\"daethyra/rag-prompt\")\n",
    "prompt3 = hub.pull(\"godk/korean-rag\")\n",
    "\n",
    "# 가져온 prompt들을 prompts list에 저장\n",
    "prompts = [prompt1, prompt2, prompt3]\n",
    "\n",
    "# Prompts 디렉토리에 prompt 저장\n",
    "for i in range(1, 4):\n",
    "    # 파일 경로를 .\\Prompts\\prompt.txt 형태로 설정\n",
    "    file_path = os.path.join(\".\\Prompts\", f\"prompt{i}.txt\")\n",
    "    \n",
    "    # format()으로 ChatPromptTemplate을 str 타입으로 변환\n",
    "    prompt = prompts[i-1].format(question=\"{question}\", context=\"{context}\")\n",
    "    \n",
    "    # 설정한 파일 경로로 변환한 prompt.txt 저장\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii. 각 프롬프트를 외부에서 불러와서 실행할 수 있도록 코드를 고쳐주세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: {question} \n",
      "Context: {context} \n",
      "Answer:\n",
      "\n",
      "\n",
      "Human: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: {question} \n",
      "Context: {context} \n",
      "Answer:\n",
      "\n",
      "\n",
      "System: You are an expert AI on a question and answer task. \n",
      "Use the \"Following Context\" when answering the question. If you don't know the answer, reply to the \"Following Text\" in the header and answer to the best of your knowledge, or if you do know the answer, answer without the \"Following Text\". If a question is asked in Korean, translate it to English and always answer in Korean.\n",
      "Following Text: \"주어진 정보에서 답변을 찾지는 못했지만, 제가 아는 선에서 답을 말씀드려볼게요! **틀릴 수도 있으니 교차검증은 필수입니다!**\"\n",
      "    \n",
      "Following Context: {context}\n",
      "Question: {question}\n",
      "Helpful Answer:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = {}\n",
    "for i in range(1, 4):\n",
    "    file_path = os.path.join(\".\\Prompts\", f\"prompt{i}.txt\")\n",
    "    with open(file_path, 'r') as f:\n",
    "        prompts[f\"prompt{i}\"] = f.read()\n",
    "        print(prompts[f\"prompt{i}\"], end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii.실행 결과는 자동으로 Results 디렉토리에 저장되어야 합니다. 이때, 실험 결과 파일 이름은 실험에 쓰인 프롬프트의 이름과 timestamp을 포함해야합니다.\n",
    "```bash\n",
    ".\n",
    "├── main.jupynb\n",
    "└── Prompts/\n",
    "    ├── prompt1.txt\n",
    "    ├── prompt2.txt\n",
    "    └── prompt3.txt\n",
    "└── Results/\n",
    "    ├── prompt1_result_1731314042.txt\n",
    "    ├── prompt2_result_1731314050.txt\n",
    "    └── prompt3_result_1731314050.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "class DebugPassThrough(RunnablePassthrough):\n",
    "    def invoke(self, *args, **kwargs):\n",
    "        output = super().invoke(*args, **kwargs)\n",
    "        print(\"Debug Output:\", output)\n",
    "        return output\n",
    "# 문서 리스트를 텍스트로 변환하는 단계 추가\n",
    "class ContextToText(RunnablePassthrough):\n",
    "    def invoke(self, inputs, config=None, **kwargs):  # config 인수 추가\n",
    "        # context의 각 문서를 문자열로 결합\n",
    "        context_text = \"\\n\".join([doc.page_content for doc in inputs[\"context\"]])\n",
    "        return {\"context\": context_text, \"question\": inputs[\"question\"]}\n",
    "    \n",
    "# Results 디렉토리가 없다면 Results 디렉토리 만들기\n",
    "os.makedirs(\"Results\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "Debug Output: 일본의 AI연구소에 대해 알려줘\n",
      "Debug Output: {'context': [Document(metadata={'source': 'files/인공지능산업최신동향_2024년_11월호.pdf', 'page': 1}, page_content='AI 연구에서 국제협력을 위한 ‘글로벌 AI 연구 의제’ 발표························13   ▹ 일본 AI안전연구소, AI 안전성에 대한 평가 관점 가이드')], 'question': '일본의 AI연구소에 대해 알려줘'}\n",
      "Final Response:\n",
      "일본에는 AI 안전 연구소가 있으며, 이 연구소는 AI 안전성에 대한 평가 관점 가이드를 제공합니다. 또한, 일본은 AI 연구에서 국제 협력을 위한 '글로벌 AI 연구 의제'를 발표했습니다. 이를 통해 AI 기술의 안전성과 발전을 동시에 추구하고 있습니다.\n",
      "========================\n",
      "Debug Output: 한국의 카카오가 선보인 최신 AI 서비스가 뭐지?\n",
      "Debug Output: {'context': [Document(metadata={'source': 'files/인공지능산업최신동향_2024년_11월호.pdf', 'page': 13}, page_content='등의 단어를 조합한 카나나는 ‘가장 나다운 AI’를 의미∙카카오는 동 브랜드를 자사가 개발하는 주요 AI 모델과 신규 서비스의 이름에 두루 사용할 계획으로, AI 메이트 서비스')], 'question': '한국의 카카오가 선보인 최신 AI 서비스가 뭐지?'}\n",
      "Final Response:\n",
      "한국의 카카오는 '카나나'라는 최신 AI 서비스를 선보였습니다. 이 서비스는 '가장 나다운 AI'를 의미하며, 카카오는 이를 자사가 개발하는 주요 AI 모델과 신규 서비스의 이름으로 사용할 계획입니다.\n",
      "========================\n",
      "Debug Output: 2024년에 있는 주요 행사들에 대해 요약해줘\n",
      "Debug Output: {'context': [Document(metadata={'source': 'files/인공지능산업최신동향_2024년_11월호.pdf', 'page': 0}, page_content='2024년 11월호')], 'question': '2024년에 있는 주요 행사들에 대해 요약해줘'}\n",
      "Final Response:\n",
      "2024년에는 여러 주요 행사들이 예정되어 있습니다. 가장 주목할 만한 행사 중 하나는 2024년 파리 올림픽입니다. 이 대회는 7월 26일부터 8월 11일까지 개최되며, 전 세계의 선수들이 모여 경쟁하게 됩니다. 또한, 2024년 미국 대선도 중요한 정치적 행사로, 11월에 이루어질 예정입니다. 이 외에도 다양한 문화 행사와 축제가 세계 여러 나라에서 개최될 예정입니다. 각 행사에 대한 구체적인 일정이나 세부 사항은 추가적인 정보가 필요합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "import time\n",
    "\n",
    "for i in range(1, 4):\n",
    "    prompt_template = prompts[f\"prompt{i}\"]\n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "    \n",
    "    # RAG 체인에서 각 단계마다 DebugPassThrough 추가\n",
    "    rag_chain_debug = {\n",
    "        \"context\": retriever,  # 컨텍스트를 가져오는 retriever\n",
    "        \"question\": DebugPassThrough()  # 사용자 질문이 그대로 전달되는지 확인하는 passthrough\n",
    "    }  | DebugPassThrough() | ContextToText() | prompt | model\n",
    "        \n",
    "    print(\"========================\")\n",
    "    query = input(\"질문을 입력하세요: \")\n",
    "    response = rag_chain_debug.invoke(query)\n",
    "    print(\"Final Response:\")\n",
    "    print(response.content)\n",
    "    \n",
    "    # timestamp 생성\n",
    "    timestamp = str(time.time()).split('.')[0]\n",
    "    \n",
    "    # 파일 경로를 .\\Results\\prompt_result_timestamp.txt 형태로 설정\n",
    "    file_path = os.path.join(\".\\Results\", f\"prompt{i}_result_{timestamp}.txt\")\n",
    "    \n",
    "    # 설정한 파일 경로로 prompt_result_timestamp.txt 저장\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
